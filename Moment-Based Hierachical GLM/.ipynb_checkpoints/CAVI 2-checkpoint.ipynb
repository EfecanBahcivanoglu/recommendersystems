{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dfdfbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import digamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af40fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('unique_userid_sample_1.csv')\n",
    "df1.drop(df1.columns[1:10], axis = 1, inplace = True)\n",
    "df1.rename(columns = {'count': 'Count', 'group': 'UserId', 'movie_id':'ItemId'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26ff44c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data structure\n",
    "# Note: Replace this with your actual dataframe\n",
    "\n",
    "\n",
    "# Ensure every user and every item that is in the validation set is also in the training set\n",
    "def create_validation_set(df, val_size=0.2):\n",
    "    # Start by shuffling the dataframe to ensure randomness\n",
    "    users = df['UserId'].unique()\n",
    "    items = df['ItemId'].unique()\n",
    "\n",
    "    # Create a mask to filter validation set\n",
    "    mask = df.duplicated(subset=['UserId'], keep=False) & df.duplicated(subset=['ItemId'], keep=False)\n",
    "    temp_df = df[mask]\n",
    "\n",
    "    # Now let's take the top `val_size` proportion of this temporary dataframe for validation\n",
    "    val_count = int(len(temp_df) * val_size)\n",
    "    validation_set = temp_df.head(val_count)\n",
    "    training_set = pd.concat([df, validation_set]).drop_duplicates(keep=False)\n",
    "\n",
    "    # Ensure that all users and items in the validation set are also in the training set\n",
    "    validation_set = validation_set[validation_set['UserId'].isin(training_set['UserId'])]\n",
    "    validation_set = validation_set[validation_set['ItemId'].isin(training_set['ItemId'])]\n",
    "\n",
    "    # Adjust the training set in case any validation rows are left\n",
    "    training_set = pd.concat([training_set, validation_set]).drop_duplicates(keep=False)\n",
    "\n",
    "    return training_set, validation_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cd864c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the validation set\n",
    "training_set, validation_set = create_validation_set(df1)\n",
    "\n",
    "# Display the sizes of the datasets to check the ratio\n",
    "(training_set.shape[0], validation_set.shape[0])\n",
    "# Fill missing observations with 0\n",
    "interaction_matrix = training_set.pivot_table(index='ItemId', columns='UserId', values='Count', fill_value=0)\n",
    "\n",
    "\n",
    "values_users = [i for i in range(len(interaction_matrix))]\n",
    "user_dict = {k:v for (k,v) in zip(interaction_matrix.columns, values_users)}\n",
    "values_items = [i for i in range(len(interaction_matrix))]\n",
    "item_dict = {k:v for (k,v) in zip(interaction_matrix.index, values_items)}\n",
    "\n",
    "y_iu = interaction_matrix.values\n",
    "y_ui = y_iu.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31702974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiliaze_parameters(num_users, num_items, k, a=0.3, a_prime=0.3, c=0.3, c_prime=0.3, b_prime=1.0, d_prime=1.0):\n",
    "    \n",
    "    k_shp = (a_prime + k * a) * np.ones(num_users)\n",
    "    t_shp = (c_prime + k * c) * np.ones(num_items)\n",
    "    k_rte = 1 * np.ones(num_users)\n",
    "    t_rte = 1 * np.ones(num_items)\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    gamma_rte = a_prime + 0.01 * rng.random((num_users, k))\n",
    "    gamma_shp = a_prime + 0.01 * rng.random((num_users, k))\n",
    "    lambda_rte = c_prime + 0.01 * rng.random((num_items, k))\n",
    "    lambda_shp = c_prime + 0.01 * rng.random((num_items, k))\n",
    "    \n",
    "    phi = np.empty((num_users, num_items, k))\n",
    "    \n",
    "    return gamma_shp, gamma_rte, lambda_shp, lambda_rte, k_shp, k_rte, t_shp, t_rte, phi, a, a_prime, c, c_prime, b_prime, d_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ea54b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAVI(num_users, num_items, k, y_ui, gamma_shp, gamma_rte, lambda_shp, lambda_rte, k_shp, k_rte, t_shp, t_rte, phi, a=0.3, a_prime=0.3, c=0.3, c_prime=0.3, b_prime=1.0, d_prime=1.0):\n",
    "    \n",
    "    # Update phi\n",
    "    phi = digamma(gamma_shp)[:, None, :] - np.log(gamma_rte)[:, None, :] \\\n",
    "          + digamma(lambda_shp)[None, :, :] - np.log(lambda_rte)[None, :, :]\n",
    "    phi -= np.max(phi, axis=2, keepdims=True)  # for numerical stability\n",
    "    np.exp(phi, out=phi)  # in-place exponentiation\n",
    "    phi /= np.sum(phi, axis=2, keepdims=True)\n",
    "    \n",
    "    print('Phi updated')\n",
    "    \n",
    "    # Users (Theta) - Gamma Shape Update\n",
    "    gamma_shp = a + np.einsum('ui, uik -> uk', y_ui, phi)\n",
    "    \n",
    "    print('Users (Theta) - Gamma Shape Updated')\n",
    "    \n",
    "    # Users (Theta) - Gamma Rate Update\n",
    "    gamma_rte = k_shp[:, None] / k_rte[:, None] + np.einsum('ik, uik -> uk', lambda_shp / lambda_rte, phi)\n",
    "    \n",
    "    print('Users (Theta) - Gamma Rate Updated')\n",
    "    \n",
    "    # Users Activity - Gamma Rate Update\n",
    "    k_rte = a_prime / b_prime + np.sum(gamma_shp / gamma_rte, axis=1)\n",
    "    \n",
    "    print('Users Activity - Gamma Rate Updated')\n",
    "    \n",
    "    # Items (Beta) - Gamma Shape Update\n",
    "    lambda_shp = c + np.einsum('ui, uik -> ik', y_ui, phi)\n",
    "    \n",
    "    print('Items (Beta) - Gamma Shape Updated')\n",
    "    \n",
    "    # Items (Beta) - Gamma Rate Update\n",
    "    lambda_rte = t_shp[:, None] / t_rte[:, None] + np.einsum('uk, uik -> ik', gamma_shp / gamma_rte, phi)\n",
    "    \n",
    "    print('Items (Beta) - Gamma Rate Updated')\n",
    "    \n",
    "    # Item Popularity - Gamma Rate Update\n",
    "    t_rte = c_prime / d_prime + np.sum(lambda_shp / lambda_rte, axis=1)\n",
    "    \n",
    "    print('Item Popularity - Gamma Rate Updated')\n",
    "    \n",
    "    return gamma_shp, gamma_rte, lambda_shp, lambda_rte, k_shp, k_rte, t_shp, t_rte, phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ff33f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation(gamma_shp, gamma_rte, lambda_shp, lambda_rte, k, y_ui):\n",
    "    \n",
    "    num_users = y_ui.shape[0]\n",
    "    num_items = y_ui.shape[1]\n",
    "    \n",
    "    ev_theta = np.empty((num_users,k))\n",
    "    ev_beta = np.empty((num_items,k))\n",
    "    for u in range(num_users):\n",
    "        for d in range(k):\n",
    "            ev_theta[u,d] = gamma_shp[u,d] / gamma_rte[u,d]\n",
    "\n",
    "    for i in range(num_items):\n",
    "        for d in range(k):\n",
    "            ev_beta[i,d] = lambda_shp[i,d] / lambda_rte[i,d]\n",
    "            \n",
    "    return ev_theta, ev_beta\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "946545f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(ev_theta, ev_beta, user_dict, item_dict, validation_set):\n",
    "    likelihood_parameters = np.matmul(ev_theta, ev_beta.T)\n",
    "    llk = 0\n",
    "    for v in range(len(validation_set)):\n",
    "        uu = validation_set['UserId'].iloc[v]\n",
    "        ii = validation_set['ItemId'].iloc[v]\n",
    "        u = user_dict[uu]\n",
    "        i = item_dict[ii]\n",
    "        value = validation_set['Count'].iloc[v]\n",
    "        llk += - likelihood_parameters[u,i] - np.log(np.math.factorial(value)) + np.log(likelihood_parameters[u,i])*value\n",
    "    return llk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ac8cc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 0\n",
      "Phi updated\n",
      "Users (Theta) - Gamma Shape Updated\n",
      "Users (Theta) - Gamma Rate Updated\n",
      "Users Activity - Gamma Rate Updated\n",
      "Items (Beta) - Gamma Shape Updated\n",
      "Items (Beta) - Gamma Rate Updated\n",
      "Item Popularity - Gamma Rate Updated\n",
      "-232882.0472536995\n",
      "Iteration number 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7c/zq5pjc5156v6v5k591lqrbgc0000gp/T/ipykernel_5974/823364683.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if ((results[-1] - results[-2])/ np.abs(results[-2])) < 0.000001:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi updated\n",
      "Users (Theta) - Gamma Shape Updated\n",
      "Users (Theta) - Gamma Rate Updated\n",
      "Users Activity - Gamma Rate Updated\n",
      "Items (Beta) - Gamma Shape Updated\n",
      "Items (Beta) - Gamma Rate Updated\n",
      "Item Popularity - Gamma Rate Updated\n",
      "-236080.44355552742\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "results = []\n",
    "gamma_shp, gamma_rte, lambda_shp, lambda_rte, k_shp, k_rte, t_shp, t_rte, phi, a, a_prime, c, c_prime, b_prime, d_prime = initiliaze_parameters(y_ui.shape[0], y_ui.shape[1], k=5, a=0.3, a_prime=0.3, c=0.3, c_prime=0.3, b_prime=1.0, d_prime=1.0)\n",
    "results.append(-np.inf)\n",
    "while i < 500:\n",
    "    print(f\"Iteration number {i}\")\n",
    "    gamma_shp, gamma_rte, lambda_shp, lambda_rte, k_shp, k_rte, t_shp, t_rte, phi = CAVI(y_ui.shape[0], y_ui.shape[1], 5, y_ui, gamma_shp, gamma_rte, lambda_shp, lambda_rte, k_shp, k_rte, t_shp, t_rte, phi)\n",
    "    ev_theta, ev_beta = expectation(gamma_shp, gamma_rte, lambda_shp, lambda_rte, 5, y_ui)\n",
    "    llk = log_likelihood(ev_theta, ev_beta, user_dict, item_dict, validation_set)\n",
    "    print(llk)\n",
    "    results.append(llk)\n",
    "    if ((results[-1] - results[-2])/ np.abs(results[-2])) < 0.000001:\n",
    "        break\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e767dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-68517.8399245928, -232880.97265696622]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97916d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
